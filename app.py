# app.py
import os
import re
import unicodedata
import traceback
from typing import Optional, List, Tuple, Dict, Any

import pandas as pd
import streamlit as st
from rapidfuzz import fuzz

# =========================================
# ì„¤ì •
# =========================================
APP_TITLE = "ì‚¬ë‚´ íê¸°ë¬¼ ì²˜ë¦¬ë°©ë²• ì¡°íšŒ"
DEFAULT_XLSX = r"C:/Users/cf100/Desktop/.streamlit/íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•.xlsx"  # ê¸°ë³¸ ê²½ë¡œ (ì‚¬ì´ë“œë°”/í™˜ê²½ë³€ìˆ˜ë¡œ ë³€ê²½ ê°€ëŠ¥)

# =========================================
# ìœ í‹¸
# =========================================
def normalize_korean(s: str) -> str:
    """NFKC ì •ê·œí™” + ê³µë°± ì •ë¦¬(ê°„ë‹¨)"""
    s = unicodedata.normalize("NFKC", str(s))
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s)
    return s.strip()

# =========================================
# ë°ì´í„° ë¡œë”©
# =========================================
def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    # 'ì²˜ë¦¬ ë°©ë²• 'ì²˜ëŸ¼ ë ê³µë°±ì´ ìˆì„ ìˆ˜ ìˆì–´ strip
    df.columns = [c.strip() for c in df.columns]
    return df

@st.cache_data(show_spinner=False)
def load_data(xlsx_path: str) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    ì‹œíŠ¸:
      - 'ê´‘ì–‘ì†Œ íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•' (ë©”ì¸)
      - 'íê¸°ë¬¼ê´€ë¦¬ë²•_ì‹œí–‰ê·œì¹™_ë³„í‘œ5' (ì°¸ê³ )
    """
    if not os.path.exists(xlsx_path):
        raise FileNotFoundError(xlsx_path)

    df_main = pd.read_excel(xlsx_path, sheet_name="ê´‘ì–‘ì†Œ íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•", engine="openpyxl")
    df_ref  = pd.read_excel(xlsx_path, sheet_name="íê¸°ë¬¼ê´€ë¦¬ë²•_ì‹œí–‰ê·œì¹™_ë³„í‘œ5", engine="openpyxl")

    df_main = _normalize_columns(df_main)
    df_ref  = _normalize_columns(df_ref)

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    for req in ["íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"]:
        if req not in df_main.columns:
            raise ValueError(f"ë©”ì¸ ì‹œíŠ¸ì— '{req}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    for req in ["êµ¬ë¶„", "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"]:
        if req not in df_ref.columns:
            raise ValueError(f"ì°¸ê³  ì‹œíŠ¸ì— '{req}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ë¬¸ìì—´í™”/íŠ¸ë¦¼
    df_main["íê¸°ë¬¼ ì¢…ë¥˜"] = df_main["íê¸°ë¬¼ ì¢…ë¥˜"].astype(str).str.strip()
    df_main["ì²˜ë¦¬ ë°©ë²•"]   = df_main["ì²˜ë¦¬ ë°©ë²•"].astype(str).str.strip()
    df_ref["êµ¬ë¶„"]        = df_ref["êµ¬ë¶„"].astype(str).str.strip()
    df_ref["íê¸°ë¬¼ ì¢…ë¥˜"]  = df_ref["íê¸°ë¬¼ ì¢…ë¥˜"].astype(str).str.strip()
    df_ref["ì²˜ë¦¬ ë°©ë²•"]    = df_ref["ì²˜ë¦¬ ë°©ë²•"].astype(str).str.strip()

    return df_main, df_ref

# =========================================
# ë§¤ì¹­/ê²€ìƒ‰
# =========================================
def normalize_query(name: str, phase: Optional[str], material: str, openai_client=None) -> List[str]:
    """
    ì…ë ¥ì„ í‘œì¤€í™”ëœ í›„ë³´ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    - OpenAIê°€ ìˆìœ¼ë©´ ë™ì˜ì–´/ì˜¤íƒ€ ë³´ì • JSON ë°°ì—´ì„ ë°›ì•„ í™•ì¥(ì„ íƒ).
    - ì—†ìœ¼ë©´ ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜ í™•ì¥.
    """
    base_terms = []
    for s in [name, material, phase or ""]:
        s = (s or "").strip()
        if s:
            base_terms.append(normalize_korean(s))

    candidates = list(dict.fromkeys([t for t in base_terms if t]))  # ì¤‘ë³µ ì œê±°

    if openai_client:
        try:
            sys = "ë„ˆëŠ” ì‚¬ë‚´ íê¸°ë¬¼ ìš©ì–´ í‘œì¤€í™” ë„ìš°ë¯¸ë‹¤. ì‚¬ìš©ì ì…ë ¥ì„ í‘œì¤€ ìš©ì–´ í›„ë³´ JSON ë°°ì—´ë¡œë§Œ ë°˜í™˜í•˜ë¼."
            user = {"name": name, "phase": phase, "material": material}
            rsp = openai_client.responses.create(
                model="gpt-4o-mini",
                input=[
                    {"role": "system", "content": sys},
                    {"role": "user", "content": str(user)}
                ],
                temperature=0
            )
            text = rsp.output_text.strip()
            if text.startswith("[") and text.endswith("]"):
                import json
                arr = json.loads(text)
                arr = [normalize_korean(str(x)) for x in arr if str(x).strip()]
                candidates = list(dict.fromkeys(candidates + arr))
        except Exception:
            # ì‹¤íŒ¨ ì‹œ ë¬´ì‹œí•˜ê³  í¼ì§€ ë§¤ì¹­ë§Œ ì‚¬ìš©
            pass

    return candidates or [normalize_korean(name)]

def _score_series(series: pd.Series, query: str) -> List[Tuple[int, float]]:
    """series(íê¸°ë¬¼ ì¢…ë¥˜) ê° í•­ëª©ê³¼ query ìœ ì‚¬ë„ë¥¼ ê³„ì‚° â†’ (index, score) ë¦¬ìŠ¤íŠ¸"""
    scores = []
    qn = normalize_korean(query)
    for idx, val in series.items():
        s = normalize_korean(val)
        score = fuzz.WRatio(qn, s)  # ì¢…í•© ê°€ì¤‘ ìœ ì‚¬ë„
        scores.append((idx, float(score)))
    return scores

def search_best(df_main: pd.DataFrame, query_terms: List[str], threshold: int = 60) -> Tuple[Optional[pd.Series], Dict[str, Any]]:
    """
    1) ì •í™•/ë¶€ë¶„ ì¼ì¹˜ ìš°ì„ 
    2) í¼ì§€ ìŠ¤ì½”ì–´ ê¸°ë°˜ ìµœìƒìœ„ 1ê±´
    """
    col_name = "íê¸°ë¬¼ ì¢…ë¥˜"
    col_method = "ì²˜ë¦¬ ë°©ë²•"
    debug: Dict[str, Any] = {"match_type": "", "score": 0.0, "candidates": []}

    # 1) ì •í™•/ë¶€ë¶„ ì¼ì¹˜
    for q in query_terms:
        # ì •í™• ì¼ì¹˜
        exact = df_main[df_main[col_name].str.strip().str.lower() == q.strip().lower()]
        if len(exact) > 0:
            row = exact.iloc[0]
            debug["match_type"] = "ì •í™• ì¼ì¹˜"
            debug["score"] = 100.0
            return row, debug
        # ë¶€ë¶„ ì¼ì¹˜
        part = df_main[df_main[col_name].str.contains(q, case=False, na=False)]
        if len(part) > 0:
            row = part.iloc[0]
            debug["match_type"] = "ë¶€ë¶„ ì¼ì¹˜"
            debug["score"] = 95.0
            return row, debug

    # 2) í¼ì§€ ë§¤ì¹­
    all_scores: List[Tuple[int, float]] = []
    for q in query_terms:
        all_scores.extend(_score_series(df_main[col_name], q))
    all_scores.sort(key=lambda x: -x[1])
    top = all_scores[:10]

    debug["candidates"] = []
    seen = set()
    best_row = None
    best_score = 0.0

    for idx, sc in top:
        if idx in seen:
            continue
        seen.add(idx)
        row = df_main.loc[idx]
        debug["candidates"].append({
            "íê¸°ë¬¼ ì¢…ë¥˜": row[col_name],
            "ì²˜ë¦¬ ë°©ë²•": row[col_method],
            "score": sc
        })
        if sc > best_score:
            best_row = row
            best_score = sc

    if best_row is not None and best_score >= threshold:
        debug["match_type"] = "í¼ì§€ ë§¤ì¹­"
        debug["score"] = best_score
        return best_row, debug

    return None, debug

def find_refs(df_ref: pd.DataFrame, keyword: str, topk: int = 3) -> list[dict]:
    """ì°¸ê³ (ë²•ë ¹) ì‹œíŠ¸ì—ì„œ ìœ ì‚¬ í•­ëª© ìƒìœ„ topk ë°˜í™˜"""
    col_name = "íê¸°ë¬¼ ì¢…ë¥˜"
    col_method = "ì²˜ë¦¬ ë°©ë²•"
    col_group = "êµ¬ë¶„"

    scores = []
    key_norm = normalize_korean(keyword)
    for idx, val in df_ref[col_name].items():
        s = normalize_korean(val)
        score = fuzz.WRatio(key_norm, s)
        scores.append((idx, float(score)))

    scores.sort(key=lambda x: -x[1])
    out = []
    for idx, sc in scores[:topk]:
        row = df_ref.loc[idx]
        out.append({
            "êµ¬ë¶„": row[col_group],
            "íê¸°ë¬¼ ì¢…ë¥˜": row[col_name],
            "ì²˜ë¦¬ ë°©ë²•": row[col_method],
            "score": sc
        })
    return out

# =========================================
# Streamlit App
# =========================================
st.set_page_config(page_title=APP_TITLE, page_icon="â™»ï¸", layout="wide")

# ì„¸ì…˜ ìƒíƒœ
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.df_main = None
    st.session_state.df_ref = None
    st.session_state.xlsx_path = None
if "OPENAI_API_KEY" not in st.session_state:
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì´ˆê¸°ê°’ ì±„ìš°ê¸°(ìˆìœ¼ë©´)
    env_key = os.getenv("OPENAI_API_KEY")
    if env_key:
        st.session_state.OPENAI_API_KEY = env_key

# ê²½ë¡œ ê²°ì • ìš°ì„ ìˆœìœ„: ì‚¬ì´ë“œë°” ì…ë ¥ > í™˜ê²½ë³€ìˆ˜(DATA_XLSX) > ê¸°ë³¸ê°’
def effective_path(default_rel: str = DEFAULT_XLSX):
    sb = st.session_state.get("sidebar_path")
    if sb and sb.strip():
        return sb.strip()
    env = os.getenv("DATA_XLSX")
    if env and env.strip():
        return env.strip()
    return default_rel

def load_app_data(xlsx_path: str):
    """ë°ì´í„° ë¡œë”© + ìƒíƒœ ì €ì¥"""
    try:
        df_main, df_ref = load_data(xlsx_path)
        st.session_state.df_main = df_main
        st.session_state.df_ref = df_ref
        st.session_state.xlsx_path = xlsx_path
        st.session_state.data_loaded = True
        return True
    except FileNotFoundError:
        st.error(f"ğŸ“ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{xlsx_path}`\nê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return False
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
            st.code(traceback.format_exc())
        return False

# ---------------- Sidebar ----------------
with st.sidebar:
    st.header("ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬")

    # ì—‘ì…€ ê²½ë¡œ
    st.caption("ì—‘ì…€ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”. (ìƒëŒ€/ì ˆëŒ€ ê²½ë¡œ ê°€ëŠ¥)")
    sidebar_path = st.text_input(
        "ì—‘ì…€ íŒŒì¼ ê²½ë¡œ",
        value=st.session_state.get("sidebar_path", effective_path()),
        help="ì˜ˆ: ./data/íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•.xlsx ë˜ëŠ” C:/work/íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•.xlsx"
    )
    st.session_state.sidebar_path = sidebar_path

    if st.button("ğŸ“Š ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°/ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        st.session_state.data_loaded = False
        _ = load_app_data(effective_path())
        st.rerun()

    # ë°ì´í„° ìƒíƒœ
    if st.session_state.data_loaded:
        st.success("âœ… ë°ì´í„° ë¡œë“œë¨")
        st.info(f"ğŸ“‚ ê²½ë¡œ: `{st.session_state.xlsx_path}`")
        if st.session_state.df_main is not None:
            st.caption(f"ğŸ“‹ ë©”ì¸ ë°ì´í„°: {len(st.session_state.df_main)}ê°œ í•­ëª©")
        if st.session_state.df_ref is not None:
            st.caption(f"ğŸ“– ì°¸ê³  ë°ì´í„°: {len(st.session_state.df_ref)}ê°œ í•­ëª©")
    else:
        st.warning("âš ï¸ ë°ì´í„° ë¯¸ë¡œë“œ")

    # OpenAI API Key ì…ë ¥(ì›¹ì—ì„œ)
    st.subheader("ğŸ¤– OpenAI ì—°ê²° ì„¤ì •")
    api_key_input = st.text_input(
        "OpenAI API Key",
        type="password",
        placeholder="sk-ë¡œ ì‹œì‘í•˜ëŠ” API Key ì…ë ¥"
    )
    if api_key_input:
        st.session_state["OPENAI_API_KEY"] = api_key_input

    # ìƒíƒœ í‘œì‹œ
    if st.session_state.get("OPENAI_API_KEY"):
        st.success("ğŸ”‘ OpenAI ì—°ê²°ë¨")
    else:
        st.info("ğŸ’¡ OpenAI ë¯¸ì—°ê²° (í¼ì§€ ë§¤ì¹­ ì‚¬ìš©)")

# ---------------- Main ----------------
st.title(f"â™»ï¸ {APP_TITLE}")
st.markdown("---")

# ì²« ë¡œë“œ ì‹œ ìë™ ì‹œë„
if not st.session_state.data_loaded:
    with st.spinner("ğŸ“Š ë°ì´í„°ë¥¼ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤..."):
        load_app_data(effective_path())

if st.session_state.data_loaded:
    st.subheader("ğŸ” íê¸°ë¬¼ ì •ë³´ ì…ë ¥")
    col1, col2, col3 = st.columns([2, 1, 2])

    with col1:
        waste_name = st.text_input(
            "íê¸°ë¬¼ëª… *",
            placeholder="ì˜ˆ: íìœ , íí˜ì¸íŠ¸ ìŠ¬ëŸ¬ì§€",
            help="ì²˜ë¦¬í•˜ê³ ì í•˜ëŠ” íê¸°ë¬¼ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
        )
    with col2:
        phase = st.selectbox(
            "ì„±ìƒ",
            ["ì„ íƒì•ˆí•¨", "ê³ ì²´", "ì•¡ì²´"],
            help="íê¸°ë¬¼ì˜ ë¬¼ë¦¬ì  ìƒíƒœë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
    with col3:
        material = st.text_input(
            "ì¬ì§ˆ",
            placeholder="ì˜ˆ: PET, ê³ ë¬´, ìœ ê¸°ìš©ì œ í•¨ìœ ",
            help="íê¸°ë¬¼ì˜ ì¬ì§ˆì´ë‚˜ êµ¬ì„± ì„±ë¶„ì„ ì…ë ¥í•˜ì„¸ìš”"
        )

    st.markdown("---")
    col_center = st.columns([1, 2, 1])[1]
    with col_center:
        search_button = st.button("ğŸ” ì²˜ë¦¬ë°©ë²• ì¡°íšŒ", type="primary", use_container_width=True)

    if search_button:
        if not waste_name.strip():
            st.warning("âš ï¸ íê¸°ë¬¼ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ğŸ” ê²€ìƒ‰ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    phase_input = None if phase == "ì„ íƒì•ˆí•¨" else phase

                    # ì„ íƒì  OpenAI: ì„¸ì…˜ ìƒíƒœì˜ í‚¤ ìš°ì„  ì‚¬ìš©
                    openai_client = None
                    api_key = st.session_state.get("OPENAI_API_KEY")
                    if api_key:
                        try:
                            from openai import OpenAI
                            openai_client = OpenAI(api_key=api_key)
                        except Exception as e:
                            st.warning(f"âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. í¼ì§€ ë§¤ì¹­ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

                    # Normalize + ë§¤ì¹­
                    query_terms = normalize_query(waste_name, phase_input, material, openai_client)
                    best_row, debug_info = search_best(st.session_state.df_main, query_terms)

                    if best_row is not None:
                        st.subheader("âœ… ì²˜ë¦¬ ë°©ë²• (ì‚¬ë‚´ ê¸°ì¤€)")
                        with st.container():
                            st.success(f"**ì²˜ë¦¬ ë°©ë²•**: {best_row['ì²˜ë¦¬ ë°©ë²•']}")
                            col_details1, col_details2 = st.columns(2)
                            with col_details1:
                                st.info(f"**ë§¤ì¹­ëœ íê¸°ë¬¼**: {best_row['íê¸°ë¬¼ ì¢…ë¥˜']}")
                            with col_details2:
                                match_type = debug_info.get("match_type", "ì•Œ ìˆ˜ ì—†ìŒ")
                                score = debug_info.get("score", 0)
                                st.info(f"**ë§¤ì¹­ ë°©ì‹**: {match_type} (ìœ ì‚¬ë„: {score:.1f}%)")

                        # ë²•ë ¹ ì°¸ê³ 
                        refs = find_refs(st.session_state.df_ref, best_row["íê¸°ë¬¼ ì¢…ë¥˜"])
                        if refs:
                            st.markdown("---")
                            st.subheader("ğŸ“– ë²•ë ¹ ì°¸ê³  (íê¸°ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ê·œì¹™ ë³„í‘œ5)")
                            with st.expander("ì°¸ê³  ì •ë³´ ë³´ê¸°", expanded=False):
                                for i, ref in enumerate(refs[:3], 1):
                                    st.markdown(f"**{i}. {ref['êµ¬ë¶„']}**")
                                    st.markdown(f"- íê¸°ë¬¼ ì¢…ë¥˜: {ref['íê¸°ë¬¼ ì¢…ë¥˜']}")
                                    st.markdown(f"- ì²˜ë¦¬ ë°©ë²•: {ref['ì²˜ë¦¬ ë°©ë²•']}")
                                    if i < len(refs[:3]):
                                        st.markdown("---")
                                st.warning("âš ï¸ **ì£¼ì˜**: ë²•ë ¹ ì •ë³´ëŠ” ì°¸ê³ ì´ë©°, ì‹¤ì œ ì—…ë¬´ ì ìš©ì€ ì‚¬ë‚´ ê¸°ì¤€ì„ ìš°ì„ í•©ë‹ˆë‹¤.")

                        # ë””ë²„ê·¸
                        if debug_info.get("candidates"):
                            with st.expander("ğŸ” ê²€ìƒ‰ ìƒì„¸ ì •ë³´", expanded=False):
                                st.json({
                                    "ì…ë ¥_ì •ë³´": {
                                        "íê¸°ë¬¼ëª…": waste_name,
                                        "ì„±ìƒ": phase_input,
                                        "ì¬ì§ˆ": material,
                                        "ì •ê·œí™”ëœ_ê²€ìƒ‰ì–´": query_terms
                                    },
                                    "ë§¤ì¹­_ê²°ê³¼": debug_info
                                })
                    else:
                        st.error("âŒ ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        if debug_info.get("candidates"):
                            st.subheader("ğŸ’¡ ìœ ì‚¬í•œ í•­ëª©ë“¤")
                            for i, c in enumerate(debug_info["candidates"][:5], 1):
                                st.markdown(f"**{i}. {c['íê¸°ë¬¼ ì¢…ë¥˜']}** (ìœ ì‚¬ë„: {c['score']:.1f}%)")
                                st.markdown(f"   ì²˜ë¦¬ ë°©ë²•: {c['ì²˜ë¦¬ ë°©ë²•']}")
                        st.info("ğŸ“ ì •í™•í•œ ì²˜ë¦¬ë°©ë²•ì€ í™˜ê²½ìì›ê·¸ë£¹(061-790-8526)ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                        st.code(traceback.format_exc())
else:
    st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì˜ 'ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°/ìƒˆë¡œê³ ì¹¨'ì„ í´ë¦­í•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ğŸ’¡ ì‹œìŠ¤í…œ ë¬¸ì˜: í™˜ê²½ìì›ê·¸ë£¹(061-790-8526) | "
    "ğŸ“§ ì‹¤ì œ ì—…ë¬´ ì ìš©ì€ ì‚¬ë‚´ ê¸°ì¤€ì„ ìš°ì„ í•˜ì„¸ìš”"
    "</div>",
    unsafe_allow_html=True
)
