# app.py
import os
import re
import unicodedata
import traceback
from typing import Optional, List, Tuple, Dict, Any

import pandas as pd
import streamlit as st
from rapidfuzz import fuzz

# =========================================
# ì„¤ì •
# =========================================
APP_TITLE = "ì‚¬ë‚´ íê¸°ë¬¼ ì²˜ë¦¬ë°©ë²• ì¡°íšŒ"
# GitHub repo ë£¨íŠ¸ì— wasteinfo.xlsx ì—…ë¡œë“œ í•„ìš”
DEFAULT_XLSX = "wasteinfo.xlsx"

# =========================================
# ìœ í‹¸
# =========================================
def normalize_korean(s: str) -> str:
    """NFKC ì •ê·œí™” + ê³µë°± ì •ë¦¬"""
    s = unicodedata.normalize("NFKC", str(s))
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s)
    return s.strip()

# =========================================
# ë°ì´í„° ë¡œë”©
# =========================================
def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]  # 'ì²˜ë¦¬ ë°©ë²• ' â†’ 'ì²˜ë¦¬ ë°©ë²•'
    return df

@st.cache_data(show_spinner=False)
def load_data(xlsx_path: str) -> tuple[pd.DataFrame, pd.DataFrame]:
    if not os.path.exists(xlsx_path):
        raise FileNotFoundError(xlsx_path)

    df_main = pd.read_excel(xlsx_path, sheet_name="ê´‘ì–‘ì†Œ íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•", engine="openpyxl")
    df_ref  = pd.read_excel(xlsx_path, sheet_name="íê¸°ë¬¼ê´€ë¦¬ë²•_ì‹œí–‰ê·œì¹™_ë³„í‘œ5", engine="openpyxl")

    df_main = _normalize_columns(df_main)
    df_ref  = _normalize_columns(df_ref)

    return df_main, df_ref

# =========================================
# ë§¤ì¹­/ê²€ìƒ‰
# =========================================
def normalize_query(name: str, phase: Optional[str], material: str) -> List[str]:
    base_terms = []
    for s in [name, material, phase or ""]:
        s = (s or "").strip()
        if s:
            base_terms.append(normalize_korean(s))
    candidates = list(dict.fromkeys([t for t in base_terms if t]))
    return candidates or [normalize_korean(name)]

def _score_series(series: pd.Series, query: str) -> List[Tuple[int, float]]:
    scores = []
    qn = normalize_korean(query)
    for idx, val in series.items():
        s = normalize_korean(val)
        score = fuzz.WRatio(qn, s)
        scores.append((idx, float(score)))
    return scores

def search_best(df_main: pd.DataFrame, query_terms: List[str], threshold: int = 60):
    col_name, col_method = "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"
    debug: Dict[str, Any] = {"match_type": "", "score": 0.0, "candidates": []}

    # ì •í™•/ë¶€ë¶„ ì¼ì¹˜
    for q in query_terms:
        exact = df_main[df_main[col_name].str.strip().str.lower() == q.strip().lower()]
        if len(exact) > 0:
            row = exact.iloc[0]
            debug["match_type"] = "ì •í™• ì¼ì¹˜"
            debug["score"] = 100.0
            return row, debug
        part = df_main[df_main[col_name].str.contains(q, case=False, na=False)]
        if len(part) > 0:
            row = part.iloc[0]
            debug["match_type"] = "ë¶€ë¶„ ì¼ì¹˜"
            debug["score"] = 95.0
            return row, debug

    # í¼ì§€ ë§¤ì¹­
    all_scores = []
    for q in query_terms:
        all_scores.extend(_score_series(df_main[col_name], q))
    all_scores.sort(key=lambda x: -x[1])
    top = all_scores[:10]

    debug["candidates"] = []
    best_row, best_score = None, 0.0
    seen = set()
    for idx, sc in top:
        if idx in seen:
            continue
        seen.add(idx)
        row = df_main.loc[idx]
        debug["candidates"].append({
            "íê¸°ë¬¼ ì¢…ë¥˜": row[col_name],
            "ì²˜ë¦¬ ë°©ë²•": row[col_method],
            "score": sc
        })
        if sc > best_score:
            best_row, best_score = row, sc

    if best_row is not None and best_score >= threshold:
        debug["match_type"] = "í¼ì§€ ë§¤ì¹­"
        debug["score"] = best_score
        return best_row, debug

    return None, debug

def find_refs(df_ref: pd.DataFrame, keyword: str, topk: int = 3):
    col_name, col_method, col_group = "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•", "êµ¬ë¶„"
    scores = []
    key_norm = normalize_korean(keyword)
    for idx, val in df_ref[col_name].items():
        s = normalize_korean(val)
        score = fuzz.WRatio(key_norm, s)
        scores.append((idx, float(score)))

    scores.sort(key=lambda x: -x[1])
    out = []
    for idx, sc in scores[:topk]:
        row = df_ref.loc[idx]
        out.append({
            "êµ¬ë¶„": row[col_group],
            "íê¸°ë¬¼ ì¢…ë¥˜": row[col_name],
            "ì²˜ë¦¬ ë°©ë²•": row[col_method],
            "score": sc
        })
    return out

# =========================================
# Streamlit App
# =========================================
st.set_page_config(page_title=APP_TITLE, page_icon="â™»ï¸", layout="wide")

if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.df_main = None
    st.session_state.df_ref = None
    st.session_state.xlsx_path = None

def load_app_data(xlsx_path: str):
    try:
        df_main, df_ref = load_data(xlsx_path)
        st.session_state.df_main = df_main
        st.session_state.df_ref = df_ref
        st.session_state.xlsx_path = xlsx_path
        st.session_state.data_loaded = True
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        with st.expander("ìƒì„¸ ì˜¤ë¥˜"):
            st.code(traceback.format_exc())

with st.sidebar:
    st.header("ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬")
    if st.button("ğŸ“Š ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°/ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        st.session_state.data_loaded = False
        load_app_data(DEFAULT_XLSX)
        st.rerun()

    if st.session_state.data_loaded:
        st.success("âœ… ë°ì´í„° ë¡œë“œë¨")
        st.info(f"ğŸ“‚ ê²½ë¡œ: {st.session_state.xlsx_path}")
    else:
        st.warning("âš ï¸ ë°ì´í„° ë¯¸ë¡œë“œ")

st.title(APP_TITLE)
st.markdown("---")

if not st.session_state.data_loaded:
    with st.spinner("ğŸ“Š ë°ì´í„°ë¥¼ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤..."):
        load_app_data(DEFAULT_XLSX)

if st.session_state.data_loaded:
    waste_name = st.text_input("íê¸°ë¬¼ëª… *", placeholder="ì˜ˆ: íìœ , íí˜ì¸íŠ¸ ìŠ¬ëŸ¬ì§€")
    phase = st.selectbox("ì„±ìƒ", ["ì„ íƒì•ˆí•¨", "ê³ ì²´", "ì•¡ì²´"])
    material = st.text_input("ì¬ì§ˆ", placeholder="ì˜ˆ: PET, ê³ ë¬´, ìœ ê¸°ìš©ì œ í•¨ìœ ")

    if st.button("ğŸ” ì²˜ë¦¬ë°©ë²• ì¡°íšŒ", type="primary"):
        if not waste_name.strip():
            st.warning("âš ï¸ íê¸°ë¬¼ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            query_terms = normalize_query(waste_name, None if phase == "ì„ íƒì•ˆí•¨" else phase, material)
            best_row, debug_info = search_best(st.session_state.df_main, query_terms)

            if best_row is not None:
                st.subheader("âœ… ì²˜ë¦¬ ë°©ë²• (ì‚¬ë‚´ ê¸°ì¤€)")
                st.success(f"**ì²˜ë¦¬ ë°©ë²•**: {best_row['ì²˜ë¦¬ ë°©ë²•']}")
                st.info(f"**ë§¤ì¹­ëœ íê¸°ë¬¼**: {best_row['íê¸°ë¬¼ ì¢…ë¥˜']} / {debug_info.get('match_type')}")

                refs = find_refs(st.session_state.df_ref, best_row["íê¸°ë¬¼ ì¢…ë¥˜"])
                if refs:
                    st.markdown("---")
                    st.subheader("ğŸ“– ë²•ë ¹ ì°¸ê³  (íê¸°ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ê·œì¹™ ë³„í‘œ5)")
                    for i, ref in enumerate(refs[:3], 1):
                        st.markdown(f"**{i}. {ref['êµ¬ë¶„']}**")
                        st.markdown(f"- íê¸°ë¬¼ ì¢…ë¥˜: {ref['íê¸°ë¬¼ ì¢…ë¥˜']}")
                        st.markdown(f"- ì²˜ë¦¬ ë°©ë²•: {ref['ì²˜ë¦¬ ë°©ë²•']}")
            else:
                st.error("âŒ ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
