# app.py
import os
import re
import unicodedata
import traceback
from typing import Optional, List, Tuple, Dict, Any

import pandas as pd
import streamlit as st
from rapidfuzz import fuzz

# =========================================
# ì„¤ì •
# =========================================
APP_TITLE = "ì‚¬ë‚´ íê¸°ë¬¼ ì²˜ë¦¬ë°©ë²• ì¡°íšŒ"
DEFAULT_XLSX = "wasteinfo.xlsx"   # GitHub repo ë£¨íŠ¸ì— wasteinfo.xlsx ì—…ë¡œë“œ í•„ìš”

# =========================================
# ìœ í‹¸
# =========================================
def normalize_korean(s: str) -> str:
    """NFKC ì •ê·œí™” + ê³µë°± ì •ë¦¬"""
    s = unicodedata.normalize("NFKC", str(s))
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s)
    return s.strip()

def pick_first_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    """ë°ì´í„°í”„ë ˆì„ì—ì„œ í›„ë³´ ì»¬ëŸ¼ëª… ì¤‘ ì²« ë²ˆì§¸ë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ë°˜í™˜"""
    for c in candidates:
        if c in df.columns:
            return c
    return None

# =========================================
# ë°ì´í„° ë¡œë”©
# =========================================
def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]  # 'ì²˜ë¦¬ ë°©ë²• ' â†’ 'ì²˜ë¦¬ ë°©ë²•'
    return df

@st.cache_data(show_spinner=False)
def load_data(xlsx_path: str) -> tuple[pd.DataFrame, pd.DataFrame]:
    if not os.path.exists(xlsx_path):
        raise FileNotFoundError(xlsx_path)

    df_main = pd.read_excel(xlsx_path, sheet_name="ê´‘ì–‘ì†Œ íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•", engine="openpyxl")
    df_ref  = pd.read_excel(xlsx_path, sheet_name="íê¸°ë¬¼ê´€ë¦¬ë²•_ì‹œí–‰ê·œì¹™_ë³„í‘œ5", engine="openpyxl")

    df_main = _normalize_columns(df_main)
    df_ref  = _normalize_columns(df_ref)

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    for req in ["íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"]:
        if req not in df_main.columns:
            raise ValueError(f"ë©”ì¸ ì‹œíŠ¸ì— '{req}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    for req in ["êµ¬ë¶„", "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"]:
        if req not in df_ref.columns:
            raise ValueError(f"ì°¸ê³  ì‹œíŠ¸ì— '{req}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ë¬¸ìì—´ ì •ë¦¬
    df_main["íê¸°ë¬¼ ì¢…ë¥˜"] = df_main["íê¸°ë¬¼ ì¢…ë¥˜"].astype(str).str.strip()
    df_main["ì²˜ë¦¬ ë°©ë²•"]   = df_main["ì²˜ë¦¬ ë°©ë²•"].astype(str).str.strip()
    df_ref["êµ¬ë¶„"]        = df_ref["êµ¬ë¶„"].astype(str).str.strip()
    df_ref["íê¸°ë¬¼ ì¢…ë¥˜"]  = df_ref["íê¸°ë¬¼ ì¢…ë¥˜"].astype(str).str.strip()
    df_ref["ì²˜ë¦¬ ë°©ë²•"]    = df_ref["ì²˜ë¦¬ ë°©ë²•"].astype(str).str.strip()

    return df_main, df_ref

# =========================================
# ë§¤ì¹­/ê²€ìƒ‰
# =========================================
def normalize_query(name: str, phase: Optional[str], material: str, openai_client=None) -> List[str]:
    """
    ê¸°ë³¸ í›„ë³´: [íê¸°ë¬¼ëª…, ì¬ì§ˆ, ì„±ìƒ]
    OpenAIê°€ ìˆìœ¼ë©´ ë™ì˜ì–´/ì˜¤íƒ€ ë³´ì • í›„ë³´ë¥¼ JSON ë°°ì—´ë¡œ ë°›ì•„ ì¶”ê°€.
    """
    base_terms = []
    for s in [name, material, phase or ""]:
        s = (s or "").strip()
        if s:
            base_terms.append(normalize_korean(s))

    candidates = list(dict.fromkeys([t for t in base_terms if t]))

    if openai_client:
        try:
            sys = "ë„ˆëŠ” ì‚¬ë‚´ íê¸°ë¬¼ ìš©ì–´ í‘œì¤€í™” ë„ìš°ë¯¸ë‹¤. ì‚¬ìš©ì ì…ë ¥ì„ í‘œì¤€ ìš©ì–´ í›„ë³´ JSON ë°°ì—´ë¡œë§Œ ë°˜í™˜í•˜ë¼."
            user = {"name": name, "phase": phase, "material": material}
            rsp = openai_client.responses.create(
                model="gpt-4o-mini",
                input=[
                    {"role": "system", "content": sys},
                    {"role": "user", "content": str(user)}
                ],
                temperature=0
            )
            text = rsp.output_text.strip()
            if text.startswith("[") and text.endswith("]"):
                import json
                arr = json.loads(text)
                arr = [normalize_korean(str(x)) for x in arr if str(x).strip()]
                candidates = list(dict.fromkeys(candidates + arr))
        except Exception:
            pass

    return candidates or [normalize_korean(name)]

def _score_series(series: pd.Series, query: str) -> List[Tuple[int, float]]:
    """series(íê¸°ë¬¼ ì¢…ë¥˜) ê° í•­ëª©ê³¼ query ìœ ì‚¬ë„ ê³„ì‚° â†’ (index, score)"""
    scores = []
    qn = normalize_korean(query)
    for idx, val in series.items():
        s = normalize_korean(val)
        score = fuzz.WRatio(qn, s)
        scores.append((idx, float(score)))
    return scores

def search_best(df_main: pd.DataFrame, query_terms: List[str], threshold: int = 60) -> Tuple[Optional[pd.Series], Dict[str, Any]]:
    """ì •í™•/ë¶€ë¶„ ì¼ì¹˜ ìš°ì„  â†’ í¼ì§€ ë§¤ì¹­ ë³´ì¡°"""
    col_name, col_method = "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"
    debug: Dict[str, Any] = {"match_type": "", "score": 0.0, "candidates": []}

    # 1) ì •í™•/ë¶€ë¶„ ì¼ì¹˜
    for q in query_terms:
        exact = df_main[df_main[col_name].str.strip().str.lower() == q.strip().lower()]
        if len(exact) > 0:
            row = exact.iloc[0]
            debug["match_type"] = "ì •í™• ì¼ì¹˜"
            debug["score"] = 100.0
            return row, debug
        part = df_main[df_main[col_name].str.contains(q, case=False, na=False)]
        if len(part) > 0:
            row = part.iloc[0]
            debug["match_type"] = "ë¶€ë¶„ ì¼ì¹˜"
            debug["score"] = 95.0
            return row, debug

    # 2) í¼ì§€ ë§¤ì¹­
    all_scores: List[Tuple[int, float]] = []
    for q in query_terms:
        all_scores.extend(_score_series(df_main[col_name], q))
    all_scores.sort(key=lambda x: -x[1])
    top = all_scores[:10]

    debug["candidates"] = []
    best_row, best_score = None, 0.0
    seen = set()
    for idx, sc in top:
        if idx in seen:
            continue
        seen.add(idx)
        row = df_main.loc[idx]
        debug["candidates"].append({
            "íê¸°ë¬¼ ì¢…ë¥˜": row[col_name],
            "ì²˜ë¦¬ ë°©ë²•": row[col_method],
            "score": sc
        })
        if sc > best_score:
            best_row, best_score = row, sc

    if best_row is not None and best_score >= threshold:
        debug["match_type"] = "í¼ì§€ ë§¤ì¹­"
        debug["score"] = best_score
        return best_row, debug

    return None, debug

def find_refs(df_ref: pd.DataFrame, keyword: str, topk: int = 1) -> list[dict]:
    """ë²•ë ¹ ì°¸ê³ (ë³„í‘œ5)ì—ì„œ ìœ ì‚¬ í•­ëª© ìƒìœ„ topk ë°˜í™˜(ìš”ì²­ì— ë”°ë¼ 1ê±´ë§Œ)"""
    col_name, col_method, col_group = "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•", "êµ¬ë¶„"
    scores = []
    key_norm = normalize_korean(keyword)
    for idx, val in df_ref[col_name].items():
        s = normalize_korean(val)
        score = fuzz.WRatio(key_norm, s)
        scores.append((idx, float(score)))

    scores.sort(key=lambda x: -x[1])
    out = []
    for idx, sc in scores[:topk]:
        row = df_ref.loc[idx]
        out.append({
            "êµ¬ë¶„": row[col_group],
            "íê¸°ë¬¼ ì¢…ë¥˜": row[col_name],
            "ì²˜ë¦¬ ë°©ë²•": row[col_method],
            "score": sc
        })
    return out

# =========================================
# Streamlit App
# =========================================
st.set_page_config(page_title=APP_TITLE, page_icon="â™»ï¸", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.df_main = None
    st.session_state.df_ref = None
    st.session_state.xlsx_path = None
if "OPENAI_API_KEY" not in st.session_state:
    # â‘  Secrets â†’ â‘¡ Env â†’ (ì—†ìœ¼ë©´ None)
    try:
        secret_key = st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        secret_key = None
    env_key = os.getenv("OPENAI_API_KEY")
    st.session_state.OPENAI_API_KEY = secret_key or env_key

def load_app_data(xlsx_path: str):
    try:
        df_main, df_ref = load_data(xlsx_path)
        st.session_state.df_main = df_main
        st.session_state.df_ref = df_ref
        st.session_state.xlsx_path = xlsx_path
        st.session_state.data_loaded = True
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        with st.expander("ìƒì„¸ ì˜¤ë¥˜"):
            st.code(traceback.format_exc())

# ---------------- Sidebar ----------------
with st.sidebar:
    st.header("ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬")

    # ë°ì´í„° ë¡œë“œ/ìƒˆë¡œê³ ì¹¨
    if st.button("ğŸ“Š ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°/ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        st.session_state.data_loaded = False
        load_app_data(DEFAULT_XLSX)
        st.rerun()

    # ìƒíƒœ í‘œì‹œ
    if st.session_state.data_loaded:
        st.success("âœ… ë°ì´í„° ë¡œë“œë¨")
        st.info(f"ğŸ“‚ ê²½ë¡œ: {st.session_state.xlsx_path}")
    else:
        st.warning("âš ï¸ ë°ì´í„° ë¯¸ë¡œë“œ")

    # OpenAI Key: â‘¢ ì‚¬ì´ë“œë°” ì…ë ¥(Secrets/Envê°€ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
    st.subheader("ğŸ¤– OpenAI ì—°ê²° ì„¤ì •")
    if st.session_state.get("OPENAI_API_KEY"):
        st.success("ğŸ”‘ OpenAI í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (Secrets ë˜ëŠ” Env).")
        st.caption("ì‚¬ì´ë“œë°” ì…ë ¥ì€ Secrets/Envê°€ ì—†ì„ ë•Œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
        api_key_input = ""
    else:
        api_key_input = st.text_input(
            "OpenAI API Key",
            type="password",
            placeholder="sk-ë¡œ ì‹œì‘í•˜ëŠ” API Key ì…ë ¥"
        )
        if api_key_input:
            st.session_state["OPENAI_API_KEY"] = api_key_input
            st.success("ğŸ”‘ OpenAI í‚¤ê°€ ì„¸ì…˜ì— ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ---------------- Main ----------------
st.title(APP_TITLE)
st.markdown("---")

# ì²« ë¡œë“œ ì‹œ ìë™ ì‹œë„
if not st.session_state.data_loaded:
    with st.spinner("ğŸ“Š ë°ì´í„°ë¥¼ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤..."):
        load_app_data(DEFAULT_XLSX)

if st.session_state.data_loaded:
    # ë©”íƒ€ ì»¬ëŸ¼ íƒì§€
    dfm = st.session_state.df_main
    COL_WASTE = "íê¸°ë¬¼ ì¢…ë¥˜"
    COL_METHOD = "ì²˜ë¦¬ ë°©ë²•"
    dept_col = pick_first_col(dfm, ["ë¶€ì„œ","ë‹´ë‹¹ ë¶€ì„œ","ì²˜ë¦¬ ë¶€ì„œ","ì²˜ë¦¬ë°©ë²• ë¶€ì„œ","ê´€ë¦¬ ë¶€ì„œ","ë¶€ì„œëª…"])
    place_col = pick_first_col(dfm, ["ì¥ì†Œ","ì²˜ë¦¬ ì¥ì†Œ","ë³´ê´€ ì¥ì†Œ","ì²˜ë¦¬ ìœ„ì¹˜","ìœ„ì¹˜"])

    st.subheader("ğŸ” íê¸°ë¬¼ ì •ë³´ ì…ë ¥")
    col1, col2, col3 = st.columns([2, 1, 2])

    with col1:
        waste_name = st.text_input("íê¸°ë¬¼ëª… *", placeholder="ì˜ˆ: íìœ , íí˜ì¸íŠ¸ ìŠ¬ëŸ¬ì§€")
    with col2:
        phase = st.selectbox("ì„±ìƒ", ["ì„ íƒì•ˆí•¨", "ê³ ì²´", "ì•¡ì²´"])
    with col3:
        material = st.text_input("ì¬ì§ˆ", placeholder="ì˜ˆ: PET, ê³ ë¬´, ìœ ê¸°ìš©ì œ í•¨ìœ ")

    st.markdown("---")
    col_center = st.columns([1, 2, 1])[1]
    with col_center:
        search_button = st.button("ğŸ” ì²˜ë¦¬ë°©ë²• ì¡°íšŒ", type="primary", use_container_width=True)

    if search_button:
        if not waste_name.strip():
            st.warning("âš ï¸ íê¸°ë¬¼ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ğŸ” ê²€ìƒ‰ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    phase_input = None if phase == "ì„ íƒì•ˆí•¨" else phase

                    # OpenAI client: â‘  Secretsâ†’â‘¡Envâ†’â‘¢Sidebar ìˆœìœ¼ë¡œ ì„¸íŒ…ëœ í‚¤ ì‚¬ìš©
                    openai_client = None
                    api_key = st.session_state.get("OPENAI_API_KEY")
                    if api_key:
                        try:
                            from openai import OpenAI
                            openai_client = OpenAI(api_key=api_key)
                        except Exception as e:
                            st.warning(f"âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. í¼ì§€ ë§¤ì¹­ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

                    # Normalize + ë§¤ì¹­
                    query_terms = normalize_query(waste_name, phase_input, material, openai_client)
                    best_row, debug_info = search_best(dfm, query_terms)

                    if best_row is not None:
                        st.subheader("âœ… ì²˜ë¦¬ ë°©ë²• (ì‚¬ë‚´ ê¸°ì¤€)")
                        with st.container():
                            st.success(f"**ì²˜ë¦¬ ë°©ë²•**: {best_row[COL_METHOD]}")
                            col_details1, col_details2, col_details3 = st.columns(3)
                            with col_details1:
                                st.info(f"**ë§¤ì¹­ëœ íê¸°ë¬¼**: {best_row[COL_WASTE]}")
                            with col_details2:
                                st.info(f"**ë§¤ì¹­ ë°©ì‹**: {debug_info.get('match_type')} (ìœ ì‚¬ë„: {debug_info.get('score', 0):.1f}%)")
                            with col_details3:
                                if dept_col:
                                    st.info(f"**ë¶€ì„œ**: {best_row.get(dept_col, '')}")
                                else:
                                    st.caption("ë¶€ì„œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                        # ---------- ë²•ë ¹ í‘œì¶œ ì¡°ê±´ ----------
                        # 1) ë¶€ì„œê°€ í™˜ê²½ìì›ê·¸ë£¹ì¸ ê²½ìš°ì—ë§Œ
                        dept_val = str(best_row.get(dept_col, "")) if dept_col else ""
                        is_env_group = "í™˜ê²½ìì›ê·¸ë£¹" in dept_val

                        # 2) ì¤‘ì•™ì•¼ì ì¥/ìŠ¤í¬ë©ì•¼ë“œ ê´€ë ¨ì´ë©´ í‘œì‹œ ê¸ˆì§€
                        excluded_terms = ["ì¤‘ì•™ì•¼ì ì¥", "ìŠ¤í¬ë©ì•¼ë“œ"]
                        place_val = str(best_row.get(place_col, "")) if place_col else ""
                        method_val = str(best_row.get(COL_METHOD, ""))
                        row_text_for_exclude = " ".join([place_val, method_val]).strip()
                        is_excluded_place = any(t in row_text_for_exclude for t in excluded_terms)

                        # ë¶„ê¸°
                        if is_env_group and not is_excluded_place:
                            refs = find_refs(st.session_state.df_ref, best_row[COL_WASTE], topk=1)
                            if refs:
                                st.markdown("---")
                                st.subheader("ğŸ“– ë²•ë ¹ ì°¸ê³  (ì‹œí–‰ê·œì¹™ ë³„í‘œ5, 1ê±´)")
                                ref = refs[0]
                                st.markdown(f"- **êµ¬ë¶„**: {ref['êµ¬ë¶„']}")
                                st.markdown(f"- **íê¸°ë¬¼ ì¢…ë¥˜**: {ref['íê¸°ë¬¼ ì¢…ë¥˜']}")
                                st.markdown(f"- **ì²˜ë¦¬ ë°©ë²•**: {ref['ì²˜ë¦¬ ë°©ë²•']}")
                            else:
                                st.info("ë³„í‘œ5ì—ì„œ ì—°ê´€ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            # ì¡°ê±´ ë¯¸ì¶©ì¡± ì‹œ ë¹„í‘œì‹œ
                            reason = []
                            if not is_env_group:
                                reason.append("ë¶€ì„œâ‰ í™˜ê²½ìì›ê·¸ë£¹")
                            if is_excluded_place:
                                reason.append("ì¤‘ì•™ì•¼ì ì¥/ìŠ¤í¬ë©ì•¼ë“œ ê´€ë ¨")
                            st.caption(f"ë²•ë ¹ ì°¸ê³  ìˆ¨ê¹€: {', '.join(reason) if reason else 'ì¡°ê±´ ë¯¸ì¶©ì¡±'}")

                    else:
                        st.error("âŒ ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        if debug_info.get("candidates"):
                            st.subheader("ğŸ’¡ ìœ ì‚¬í•œ í•­ëª©ë“¤(Top)")
                            for i, c in enumerate(debug_info["candidates"][:5], 1):
                                st.markdown(f"**{i}. {c['íê¸°ë¬¼ ì¢…ë¥˜']}** (ìœ ì‚¬ë„: {c['score']:.1f}%)")
                                st.markdown(f"   ì²˜ë¦¬ ë°©ë²•: {c['ì²˜ë¦¬ ë°©ë²•']}")
                except Exception as e:
                    st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                        st.code(traceback.format_exc())
else:
    st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°/ìƒˆë¡œê³ ì¹¨'ì„ í´ë¦­í•˜ê±°ë‚˜ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ğŸ’¡ ì‹œìŠ¤í…œ ë¬¸ì˜: í™˜ê²½ìì›ê·¸ë£¹ ìì›ì¬í™œìš©ì„¹ì…˜ (790-8526) | "
    "ğŸ“§ ì‹¤ì œ ì—…ë¬´ ì ìš©ì€ ì‚¬ë‚´ ê¸°ì¤€ì„ ìš°ì„ í•˜ì„¸ìš”"
    "</div>",
    unsafe_allow_html=True
)
