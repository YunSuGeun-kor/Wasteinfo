# app.py
import os
import re
import unicodedata
import traceback
from typing import Optional, List, Tuple, Dict, Any

import pandas as pd
import streamlit as st
from rapidfuzz import fuzz

APP_TITLE = "ì‚¬ë‚´ íê¸°ë¬¼ ì²˜ë¦¬ë°©ë²• ì¡°íšŒ"
DEFAULT_XLSX = "wasteinfo.xlsx"

# ---------- ìœ í‹¸ ----------
def normalize_korean(s: str) -> str:
    s = unicodedata.normalize("NFKC", str(s))
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s)
    return s.strip()

def canon(s: str) -> str:
    """ë¹„êµìš© ì •ê·œí™”: í•œê¸€ NFKC, ì†Œë¬¸ì, ê³µë°±/í•˜ì´í”ˆ ì œê±°, ê´„í˜¸ í†µì¼"""
    t = normalize_korean(s).lower()
    t = t.replace(" ", "")
    t = t.replace("-", "")
    t = t.replace("[", "(").replace("]", ")")
    return t

def contains_key(text: str, key: str) -> bool:
    return canon(key) in canon(text or "")

# ---------- ë°ì´í„° ----------
def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    return df

@st.cache_data(show_spinner=False)
def load_data(xlsx_path: str) -> tuple[pd.DataFrame, pd.DataFrame]:
    if not os.path.exists(xlsx_path):
        raise FileNotFoundError(xlsx_path)
    df_main = pd.read_excel(xlsx_path, sheet_name="ê´‘ì–‘ì†Œ íê¸°ë¬¼ì²˜ë¦¬ë°©ë²•", engine="openpyxl")
    df_ref  = pd.read_excel(xlsx_path, sheet_name="íê¸°ë¬¼ê´€ë¦¬ë²•_ì‹œí–‰ê·œì¹™_ë³„í‘œ5", engine="openpyxl")
    df_main = _normalize_columns(df_main)
    df_ref  = _normalize_columns(df_ref)

    for req in ["íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"]:
        if req not in df_main.columns:
            raise ValueError(f"ë©”ì¸ ì‹œíŠ¸ '{req}' ì»¬ëŸ¼ ì—†ìŒ")
    for req in ["êµ¬ë¶„", "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"]:
        if req not in df_ref.columns:
            raise ValueError(f"ì°¸ê³  ì‹œíŠ¸ '{req}' ì»¬ëŸ¼ ì—†ìŒ")

    df_main["íê¸°ë¬¼ ì¢…ë¥˜"] = df_main["íê¸°ë¬¼ ì¢…ë¥˜"].astype(str).str.strip()
    df_main["ì²˜ë¦¬ ë°©ë²•"]   = df_main["ì²˜ë¦¬ ë°©ë²•"].astype(str).str.strip()
    df_ref["êµ¬ë¶„"]        = df_ref["êµ¬ë¶„"].astype(str).str.strip()
    df_ref["íê¸°ë¬¼ ì¢…ë¥˜"]  = df_ref["íê¸°ë¬¼ ì¢…ë¥˜"].astype(str).str.strip()
    df_ref["ì²˜ë¦¬ ë°©ë²•"]    = df_ref["ì²˜ë¦¬ ë°©ë²•"].astype(str).str.strip()
    return df_main, df_ref

# ---------- ë§¤ì¹­ ----------
def normalize_query(name: str, phase: Optional[str], material: str, openai_client=None) -> List[str]:
    base_terms = []
    for s in [name, material, phase or ""]:
        s = (s or "").strip()
        if s:
            base_terms.append(normalize_korean(s))
    candidates = list(dict.fromkeys([t for t in base_terms if t]))
    return candidates or [normalize_korean(name)]

def _score_series(series: pd.Series, query: str) -> List[Tuple[int, float]]:
    scores = []
    qn = normalize_korean(query)
    for idx, val in series.items():
        s = normalize_korean(val)
        score = fuzz.WRatio(qn, s)
        scores.append((idx, float(score)))
    return scores

def search_best(df_main: pd.DataFrame, query_terms: List[str], threshold: int = 60) -> Tuple[Optional[pd.Series], Dict[str, Any]]:
    col_name, col_method = "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•"
    debug: Dict[str, Any] = {"match_type": "", "score": 0.0, "candidates": []}

    for q in query_terms:
        exact = df_main[df_main[col_name].str.strip().str.lower() == q.strip().lower()]
        if len(exact) > 0:
            row = exact.iloc[0]
            debug["match_type"] = "ì •í™• ì¼ì¹˜"; debug["score"] = 100.0
            return row, debug
        part = df_main[df_main[col_name].str.contains(q, case=False, na=False)]
        if len(part) > 0:
            row = part.iloc[0]
            debug["match_type"] = "ë¶€ë¶„ ì¼ì¹˜"; debug["score"] = 95.0
            return row, debug

    all_scores: List[Tuple[int, float]] = []
    for q in query_terms:
        all_scores.extend(_score_series(df_main[col_name], q))
    all_scores.sort(key=lambda x: -x[1])
    top = all_scores[:10]

    best_row, best_score = None, 0.0
    seen = set()
    for idx, sc in top:
        if idx in seen: continue
        seen.add(idx)
        row = df_main.loc[idx]
        debug["candidates"].append({"íê¸°ë¬¼ ì¢…ë¥˜": row[col_name], "ì²˜ë¦¬ ë°©ë²•": row[col_method], "score": sc})
        if sc > best_score:
            best_row, best_score = row, sc
    if best_row is not None and best_score >= threshold:
        debug["match_type"] = "í¼ì§€ ë§¤ì¹­"; debug["score"] = best_score
        return best_row, debug
    return None, debug

def find_refs(df_ref: pd.DataFrame, keyword: str, topk: int = 1) -> list[dict]:
    col_name, col_method, col_group = "íê¸°ë¬¼ ì¢…ë¥˜", "ì²˜ë¦¬ ë°©ë²•", "êµ¬ë¶„"
    scores = []
    key_norm = normalize_korean(keyword)
    for idx, val in df_ref[col_name].items():
        s = normalize_korean(val)
        score = fuzz.WRatio(key_norm, s)
        scores.append((idx, float(score)))
    scores.sort(key=lambda x: -x[1])
    out = []
    for idx, sc in scores[:topk]:
        row = df_ref.loc[idx]
        out.append({"êµ¬ë¶„": row[col_group], "íê¸°ë¬¼ ì¢…ë¥˜": row[col_name], "ì²˜ë¦¬ ë°©ë²•": row[col_method], "score": sc})
    return out

# ---------- Streamlit ----------
st.set_page_config(page_title=APP_TITLE, page_icon="â™»ï¸", layout="wide")

if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.df_main = None
    st.session_state.df_ref = None
    st.session_state.xlsx_path = None

def load_app_data(xlsx_path: str):
    try:
        df_main, df_ref = load_data(xlsx_path)
        st.session_state.df_main = df_main
        st.session_state.df_ref = df_ref
        st.session_state.xlsx_path = xlsx_path
        st.session_state.data_loaded = True
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        with st.expander("ìƒì„¸ ì˜¤ë¥˜"):
            st.code(traceback.format_exc())

with st.sidebar:
    st.header("ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬")
    if st.button("ğŸ“Š ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°/ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        st.session_state.data_loaded = False
        load_app_data(DEFAULT_XLSX)
        st.rerun()
    if st.session_state.data_loaded:
        st.success("âœ… ë°ì´í„° ë¡œë“œë¨"); st.info(f"ğŸ“‚ ê²½ë¡œ: {st.session_state.xlsx_path}")
    else:
        st.warning("âš ï¸ ë°ì´í„° ë¯¸ë¡œë“œ")

st.title(APP_TITLE); st.markdown("---")

if not st.session_state.data_loaded:
    with st.spinner("ğŸ“Š ë°ì´í„°ë¥¼ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤..."):
        load_app_data(DEFAULT_XLSX)

if st.session_state.data_loaded:
    dfm = st.session_state.df_main
    COL_WASTE = "íê¸°ë¬¼ ì¢…ë¥˜"
    COL_METHOD = "ì²˜ë¦¬ ë°©ë²•"

    # í—ˆìš©/ë°°ì œ í‚¤
    ALLOW_KEY = "í™˜ê²½ìì›ê·¸ë£¹(790-8526)"
    EXCLUDE_KEYS = [
        "ì¤‘ì•™ì•¼ì ì¥ (ê´‘ì–‘ìì¬ì§€ì› 790-2732)",
        "ì œê°•ë¶€ ìŠ¤í¬ë©ì¥ (ì‚¼ì§„ê¸°ì—… 790-2815)",
    ]

    st.subheader("ğŸ” íê¸°ë¬¼ ì •ë³´ ì…ë ¥")
    c1, c2, c3 = st.columns([2, 1, 2])
    with c1:
        waste_name = st.text_input("íê¸°ë¬¼ëª… *", placeholder="ì˜ˆ: íìœ , íí˜ì¸íŠ¸ ìŠ¬ëŸ¬ì§€")
    with c2:
        phase = st.selectbox("ì„±ìƒ", ["ì„ íƒì•ˆí•¨", "ê³ ì²´", "ì•¡ì²´"])
    with c3:
        material = st.text_input("ì¬ì§ˆ", placeholder="ì˜ˆ: PET, ê³ ë¬´, ìœ ê¸°ìš©ì œ í•¨ìœ ")

    st.markdown("---")
    center = st.columns([1, 2, 1])[1]
    with center:
        search_button = st.button("ğŸ” ì²˜ë¦¬ë°©ë²• ì¡°íšŒ", type="primary", use_container_width=True)

    if search_button:
        if not waste_name.strip():
            st.warning("âš ï¸ íê¸°ë¬¼ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ğŸ” ê²€ìƒ‰ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    phase_input = None if phase == "ì„ íƒì•ˆí•¨" else phase
                    query_terms = normalize_query(waste_name, phase_input, material, None)
                    best_row, debug_info = search_best(dfm, query_terms)

                    if best_row is not None:
                        st.subheader("âœ… ì²˜ë¦¬ ë°©ë²• (ì‚¬ë‚´ ê¸°ì¤€)")
                        st.success(f"**ì²˜ë¦¬ ë°©ë²•**: {best_row[COL_METHOD]}")
                        cA, cB = st.columns(2)
                        with cA:
                            st.info(f"**ë§¤ì¹­ëœ íê¸°ë¬¼**: {best_row[COL_WASTE]}")
                        with cB:
                            st.info(f"**ë§¤ì¹­ ë°©ì‹**: {debug_info.get('match_type')} (ìœ ì‚¬ë„: {debug_info.get('score', 0):.1f}%)")

                        # ---------- ë²•ë ¹ í‘œì¶œ ì¡°ê±´: ì²˜ë¦¬ë°©ë²•ë§Œ ì‚¬ìš© ----------
                        method_val = str(best_row[COL_METHOD])
                        show_law = contains_key(method_val, ALLOW_KEY) and not any(
                            contains_key(method_val, k) for k in EXCLUDE_KEYS
                        )

                        if show_law:
                            refs = find_refs(st.session_state.df_ref, best_row[COL_WASTE], topk=1)
                            if refs:
                                st.markdown("---")
                                st.subheader("ğŸ“– ë²•ë ¹ ì°¸ê³  (ì‹œí–‰ê·œì¹™ ë³„í‘œ5, 1ê±´)")
                                ref = refs[0]
                                st.markdown(f"- **êµ¬ë¶„**: {ref['êµ¬ë¶„']}")
                                st.markdown(f"- **íê¸°ë¬¼ ì¢…ë¥˜**: {ref['íê¸°ë¬¼ ì¢…ë¥˜']}")
                                st.markdown(f"- **ì²˜ë¦¬ ë°©ë²•**: {ref['ì²˜ë¦¬ ë°©ë²•']}")
                            else:
                                st.info("ë³„í‘œ5ì—ì„œ ì—°ê´€ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.caption("ë²•ë ¹ ì°¸ê³  ìˆ¨ê¹€: ì¡°ê±´ ë¯¸ì¶©ì¡±(í™˜ê²½ìì›ê·¸ë£¹ ì•„ë‹ˆê±°ë‚˜ ì¤‘ì•™ì•¼ì ì¥/ìŠ¤í¬ë©ì¥)")

                    else:
                        st.error("âŒ ì¼ì¹˜ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        if debug_info.get("candidates"):
                            st.subheader("ğŸ’¡ ìœ ì‚¬í•œ í•­ëª©ë“¤(Top)")
                            for i, c in enumerate(debug_info["candidates"][:5], 1):
                                st.markdown(f"**{i}. {c['íê¸°ë¬¼ ì¢…ë¥˜']}** (ìœ ì‚¬ë„: {c['score']:.1f}%)")
                                st.markdown(f"   ì²˜ë¦¬ ë°©ë²•: {c['ì²˜ë¦¬ ë°©ë²•']}")
                except Exception as e:
                    st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                        st.code(traceback.format_exc())
else:
    st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ğŸ’¡ ì‹œìŠ¤í…œ ë¬¸ì˜: í™˜ê²½ìì›ê·¸ë£¹ ìì›ì¬í™œìš©ì„¹ì…˜ (790-8526) | "
    "ğŸ“§ ì‹¤ì œ ì—…ë¬´ ì ìš©ì€ ì‚¬ë‚´ ê¸°ì¤€ì„ ìš°ì„ í•˜ì„¸ìš”"
    "</div>",
    unsafe_allow_html=True
)
